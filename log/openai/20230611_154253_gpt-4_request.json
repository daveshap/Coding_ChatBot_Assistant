[
    {
        "content": "this is a test message",
        "role": "user"
    },
    {
        "content": "You are a Python coding assistant.\nThe USER will give you instructions to help write functions.\nYou may ask for clarification if needed, but otherwise you should only output Python code, if there are comments in the code then keep them.\nAdhere to PEP8. Provide explanations of the code only if the user asks for them.\n\nThe below code scratchpad may be provided by the user so you are aware of the script they are working on.\nNote, this information may be blank.\nEven if the below information is populated, it may not be relevant to the user's request.\nUse your best judgment to discern if the user is asking for you to modify the below code,\nor if the code is there for reference.\n\nCoding scratchpad:\n```python\nimport argparse\nimport json\nimport os\nimport textwrap\nimport time\nfrom datetime import datetime\nfrom typing import Any, Union\nfrom typing import List\n\nimport openai\n\n\nclass AppState:\n    def __init__(self):\n        self.MODEL_NAME = \"gpt-4\"\n        self.MODEL_TEMPERATURE = 0.1\n        self.MODEL_MAX_TOKENS = 7500\n        self.ALL_MESSAGES = list()\n\n\napp_state = AppState()\n\n\n# Section:    logging for debug functions\n\ndef create_log_file(suffix: str) -> str:\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    log_dir = \"log/openai\"\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    log_file = os.path.join(log_dir, f\"{timestamp}{suffix}\")\n    return log_file\n\n\ndef save_request_as_human_readable_text(conversation, suffix):\n    log_file = create_log_file(suffix)\n    human_readable_text = \"\"\n    for message in conversation:\n        if 'role' in message and 'content' in message:\n            human_readable_text += f\"# {message['role'].upper()}:\\n{message['content']}\\n\\n\"\n        else:\n            print(f\"Skipping message due to missing 'role' or 'content': {message}\")\n    save_content_to_file(log_file, human_readable_text)\n\n\ndef save_response_as_human_readable_text(response, total_tokens, duration, suffix=\"\"):\n    log_file = create_log_file(suffix)\n    conversation: List[dict] = response[\"choices\"]\n    human_readable_text = f\"- Model      : {app_state.MODEL_NAME}\\n\"\n    human_readable_text += f\"- Temperature: {app_state.MODEL_TEMPERATURE}\\n\"\n    human_readable_text += f\"- Tokens     : {total_tokens}\\n\"\n    human_readable_text += f\"- Duration   : {duration}\\n\"\n    human_readable_text += \"\\n\\n\"\n    for message in conversation:\n        message = message[\"message\"]\n        if 'role' in message and 'content' in message:\n            human_readable_text += f\"# {message['role'].upper()}:\\n{message['content']}\\n\\n\"\n        else:\n            print(f\"Skipping message due to missing 'role' or 'content': {message}\")\n    save_content_to_file(log_file, human_readable_text)\n\n\ndef pretty_print_json(conversation: Any) -> Union[str, Any]:\n    try:\n        return json.dumps(conversation, indent=4, sort_keys=True)\n    except Exception:\n        return conversation\n\n\ndef save_json_log(conversation, suffix, pretty_print=True):\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    log_dir = \"log/openai\"\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    log_file = os.path.join(log_dir, f\"{timestamp}{suffix}.json\")\n    if pretty_print:\n        conversation = pretty_print_json(conversation)\n    save_content_to_file(log_file, str(conversation))\n\n\n# Section:     file operations\n\ndef save_content_to_file(filepath, content):\n    with open(filepath, 'w', encoding='utf-8') as outfile:\n        outfile.write(content)\n\n\ndef read_file_content(filepath):\n    with open(filepath, 'r', encoding='utf-8', errors='ignore') as infile:\n        return infile.read()\n\n\n# Section:     API functions\n\ndef get_chatbot_response(conversation: List[dict]) -> dict:\n    return openai.ChatCompletion.create(\n        model=app_state.MODEL_NAME,\n        messages=conversation,\n        temperature=app_state.MODEL_TEMPERATURE,\n        # max_tokens=app_state.MODEL_MAX_TOKENS,\n    )\n\n\ndef handle_error(error, conversation):\n    print(f'\\n\\nError communicating with OpenAI: \"{error}\"')\n    if 'maximum context length' in str(error):\n        conversation.pop(0)\n        print('\\n\\n DEBUG: Trimming oldest message')\n        return True, conversation\n    return False, conversation\n\n\ndef perform_chatbot_conversation(conversation: List[dict]) -> tuple[Any, Any, float]:\n    max_retry: int = 7\n\n    # Save the conversation to a log file\n    save_json_log(conversation, f'_{app_state.MODEL_NAME}_request')\n    save_request_as_human_readable_text(conversation, f\"_{app_state.MODEL_NAME}_request.md\")\n\n    for retry in range(max_retry):\n        try:\n            start_time = time.time()\n            print(\"INFO: Processing...\")\n\n            response = get_chatbot_response(conversation)\n            text = response['choices'][0]['message']['content']\n            total_tokens = response['usage']['total_tokens']\n\n            end_time = time.time()\n            processing_time = end_time - start_time\n\n            save_json_log(response, f'_{total_tokens}_response', False)\n            save_response_as_human_readable_text(\n                response, total_tokens, processing_time,\n                f\"_{total_tokens}_response.md\",\n            )\n\n            return text, total_tokens, processing_time\n        except Exception as oops:\n            should_continue, conversation = handle_error(oops, conversation)\n            if not should_continue:\n                wait_time = 2 ** retry * 5\n                print(f'\\n\\nRetrying in {wait_time} seconds...')\n                time.sleep(wait_time)\n            else:\n                continue\n\n    print(f\"\\n\\nExiting due to excessive errors in API.\")\n    exit(1)\n\n\n###     MAIN LOOP\n\n\ndef multi_line_input():\n    print('\\n\\n\\nType END to save and exit.\\n[MULTI] USER:\\n')\n    lines = []\n    while True:\n        line = input()\n        if line == \"END\":\n            break\n        lines.append(line)\n    return \"\\n\".join(lines)\n\n\ndef get_user_input():\n    # get user input\n    text = input(f'[{app_state.MODEL_NAME}] USER PROMPT: ')\n    if 'END' == text:\n        print('\\n\\nExiting...')\n        exit(0)\n    if 'SCRATCHPAD' == text or 'M' == text:\n        text = multi_line_input()\n        save_content_to_file('scratchpad.md', text.strip('END').strip())\n        print('\\n\\n#####      Scratchpad updated!')\n        return None\n    return text\n\n\ndef print_chatbot_response(response, total_tokens, processing_time):\n    print('\\n\\n\\n\\nCHATBOT response:\\n')\n    formatted_lines = [textwrap.fill(line, width=120) for line in response.split('\\n')]\n    formatted_text = '\\n'.join(formatted_lines)\n    print(formatted_text)\n    print(f'\\n\\nINFO: {app_state.MODEL_NAME}: {total_tokens} tokens, {processing_time:.2f} seconds')\n\n\ndef main():\n    # instantiate chatbot\n    openai.api_key = read_file_content('key_openai.txt').strip()\n\n    # parse arguments\n    parser = argparse.ArgumentParser(description=\"Chatbot using OpenAI API\")\n    parser.add_argument(\"--model\", default=app_state.MODEL_NAME,\n                        help=\"Model name (default: %(default)s)\")\n    parser.add_argument(\"--temperature\", type=float, default=app_state.MODEL_TEMPERATURE,\n                        help=\"Temperature (default: %(default)s)\")\n    args, unknown = parser.parse_known_args()\n\n    app_state.MODEL_NAME = args.model\n    app_state.MODEL_TEMPERATURE = args.temperature\n\n    print(f\"Current settings:\\n\"\n          f\"Model: {app_state.MODEL_NAME}\\n\"\n          f\"Temperature: {app_state.MODEL_TEMPERATURE}\")\n    print(\"Sample app usage: python chat.py --model gpt-3.5-turbo --temperature 0.2\")\n\n\n    print(\"\\n\\n****** IMPORTANT ******\\n\"\n          \"Type 'SCRATCHPAD' or 'M' to enter multi-line input mode to update the scratchpad.\\n\"\n          \"Type 'END' to save and exit.\\n\")\n\n    while True:\n        text = get_user_input()\n        if text is None:\n            continue\n        if text == '':\n            # empty submission, probably on accident\n            continue\n\n        # continue with composing conversation and response\n        app_state.ALL_MESSAGES.append({'role': 'user', 'content': text})\n        system_message = read_file_content('system_message.txt').replace('<<CODE>>', read_file_content('scratchpad.md'))\n        conversation = list()\n        conversation += app_state.ALL_MESSAGES\n        conversation.append({'role': 'system', 'content': system_message})\n\n        # generate a response\n        response, tokens, processing_time = perform_chatbot_conversation(conversation)\n\n        if tokens > app_state.MODEL_MAX_TOKENS:\n            app_state.ALL_MESSAGES.pop(0)\n\n        app_state.ALL_MESSAGES.append({'role': 'assistant', 'content': response})\n        print_chatbot_response(response, tokens, processing_time)\n\n\nif __name__ == '__main__':\n    main()\n\n```",
        "role": "system"
    }
]